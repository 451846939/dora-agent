mod tools;

use std::process::exit;
use dora_node_api::{self, DoraNode, Event, IntoArrow};
use rig::completion::Prompt;
use rig::providers;
use common::{register_id, result_id};
use crate::tools::web_search::{SearchResult, SearchWebArgs};
use anyhow::Context;
use common::config::{AppConfig};
use common::descriptor::NodeDescriptor;
use common::message::FlowMessage;

#[tokio::main]
async fn main() -> eyre::Result<()> {
    println!("üöÄ start web-search");
    let (mut node, mut events) = DoraNode::init_from_env()?;
    let app_id = "web_search".to_string();
    let (openai_client,config)=AppConfig::from_file_with_appid(&app_id)?;
    while let Some(event) = events.recv_async().await {
        match event {
            Event::Input {
                id,
                metadata,
                data,
            } => match id.as_str() {
                "web_search" => {
                    // ‰ªéÊï∞ÊçÆ‰∏≠Ëß£ÊûêÂá∫Áªü‰∏ÄÁöÑ FlowMessage
                    let flow_msg: FlowMessage = FlowMessage::try_from(data)
                        .context("expected FlowMessage").unwrap();
                    println!("sink received FlowMessage: {:?}", flow_msg);
                    let received_string = if let Some(s) = flow_msg.input.as_str() {
                        s.to_string()
                    } else {
                        serde_json::to_string(&flow_msg.input)?
                    };
                    let openai_client = providers::ollama::Client::new();

                    let agent = openai_client
                        .agent(&config.model)
                        .preamble("‰Ω†ÊòØ‰∏Ä‰∏™ÊêúÁ¥¢Âä©ÊâãÔºåÂèØ‰ª•‰ΩøÁî® search_web Â∑•ÂÖ∑Êù•ÊâßË°åÊêúÁ¥¢‰ªªÂä°,‰Ω†Â∫îËØ•Âà§Êñ≠‰ΩøÁî® search_web Âπ∂Â∞Ü click ËÆæÁΩÆ‰∏∫ trueÔºåÂê¶Âàô‰∏çÁÇπÂáª„ÄÇ")
                        .max_tokens(1024)
                        .tool(crate::tools::web_search::SearchWebTool)
                        .build();
                    let web_search_json = agent.prompt(received_string).await?;
                    let web_search_json =web_search_json.as_str();
                    // let web_search_json = r#"[{"title":"The Async Ecosystem - Asynchronous Programming in Rust","link":"https://rust-lang.github.io/async-book/08_ecosystem/00_chapter.html","content":"The Async Ecosystem\nRust currently provides only the bare essentials for writing async code. Importantly, executors, tasks, reactors, combinators, and low-level I/O futures and traits are not yet provided in the standard library. In the meantime, community-provided async ecosystems fill in these gaps.\nThe Async Foundations Team is interested in extending examples in the Async Book to cover multiple runtimes. If you're interested in contributing to this project, please reach out to us on Zulip.\nAsync Runtimes\nAsync runtimes are libraries used for executing async applications. Runtimes usually bundle together a reactor with one or more executors. Reactors provide subscription mechanisms for external events, like async I/O, interprocess communication, and timers. In an async runtime, subscribers are typically futures representing low-level I/O operations. Executors handle the scheduling and execution of tasks. They keep track of running and suspended tasks, poll futures to completion, and wake tasks when they can make progress. The word \"executor\" is frequently used interchangeably with \"runtime\". Here, we use the word \"ecosystem\" to describe a runtime bundled with compatible traits and features.\nCommunity-Provided Async Crates\nThe Futures Crate\nThe futures crate contains traits and functions useful for writing async code. This includes the Stream, Sink, AsyncRead, and AsyncWrite traits, and utilities such as combinators. These utilities and traits may eventually become part of the standard library.\nfutures has its own executor, but not its own reactor, so it does not support execution of async I/O or timer futures. For this reason, it's not considered a full runtime. A common choice is to use utilities from futures with an executor from another crate.\nPopular Async Runtimes\nThere is no asynchronous runtime in the standard library, and none are officially recommended. The following crates provide popular runtimes.\nTokio: A popular async ecosystem with HTTP, gRPC, and tracing frameworks.\nasync-std: A crate that provides asynchronous counterparts to standard library components.\nsmol: A small, simplified async runtime. Provides the Async trait that can be used to wrap structs like UnixStream or TcpListener.\nfuchsia-async: An executor for use in the Fuchsia OS.\nDetermining Ecosystem Compatibility\nNot all async applications, frameworks, and libraries are compatible with each other, or with every OS or platform. Most async code can be used with any ecosystem, but some frameworks and libraries require the use of a specific ecosystem. Ecosystem constraints are not always documented, but there are several rules of thumb to determine whether a library, trait, or function depends on a specific ecosystem.\nAny async code that interacts with async I/O, timers, interprocess communication, or tasks generally depends on a specific async executor or reactor. All other async code, such as async expressions, combinators, synchronization types, and streams are usually ecosystem independent, provided that any nested futures are also ecosystem independent. Before beginning a project, it's recommended to research relevant async frameworks and libraries to ensure compatibility with your chosen runtime and with each other.\nNotably, Tokio uses the mio reactor and defines its own versions of async I/O traits, including AsyncRead and AsyncWrite. On its own, it's not compatible with async-std and smol, which rely on the async-executor crate, and the AsyncRead and AsyncWrite traits defined in futures.\nConflicting runtime requirements can sometimes be resolved by compatibility layers that allow you to call code written for one runtime within another. For example, the async_compat crate provides a compatibility layer between Tokio and other runtimes.\nLibraries exposing async APIs should not depend on a specific executor or reactor, unless they need to spawn tasks or define their own async I/O or timer futures. Ideally, only binaries should be responsible for scheduling and running tasks.\nSingle Threaded vs Multi-Threaded Executors\nAsync executors can be single-threaded or multi-threaded. For example, the async-executor crate has both a single-threaded LocalExecutor and a multi-threaded Executor.\nA multi-threaded executor makes progress on several tasks simultaneously. It can speed up the execution greatly for workloads with many tasks, but synchronizing data between tasks is usually more expensive. It is recommended to measure performance for your application when you are choosing between a single- and a multi-threaded runtime.\nTasks can either be run on the thread that created them or on a separate thread. Async runtimes often provide functionality for spawning tasks onto separate threads. Even if tasks are executed on separate threads, they should still be non-blocking. In order to schedule tasks on a multi-threaded executor, they must also be Send. Some runtimes provide functions for spawning non-Send tasks, which ensures every task is executed on the thread that spawned it. They may also provide functions for spawning blocking tasks onto dedicated threads, which is useful for running blocking synchronous code from other libraries."},{"title":"The State of Async Rust: Runtimes | corrode Rust Consulting","link":"https://corrode.dev/blog/async/","content":"Rust Insights\nThe State of Async Rust: Runtimes\nLast updated 2024-04-27\nRecently, I found myself returning to a compelling series of blog posts titled Zero-cost futures in Rust by Aaron Turon about what would become the foundation of Rust‚Äôs async ecosystem and the Tokio runtime.\nThis series stands as a cornerstone in writings about Rust. People like Aaron are the reason why I wanted to be part of the Rust community in the first place.\nWhile 2016 evokes nostalgic memories of excitement and fervor surrounding async Rust, my sentiments regarding the current state of its ecosystem are now somewhat ambivalent.\nWhy Bother?\nThrough this series, I hope to address two different audiences:\nNewcomers to async Rust, seeking to get an overview of the current state of the ecosystem.\nLibrary maintainers and contributors to the async ecosystem, in the hope that my perspective can be a basis for discussion about the future of async Rust.\nIn the first article, we will focus on the current state of async Rust runtimes, their design choices, and their implications on the broader Rust async ecosystem.\nOne True Runtime\nAn inconvenient truth about async Rust is that libraries still need to be written against individual runtimes. Writing your async code in a runtime-agnostic fashion requires conditional compilation, compatibility layers and handling edge-cases.\nThis is the rationale behind most libraries gravitating towards the One True Runtime ‚Äî Tokio.\nExecutor coupling is a big problem for async Rust as it breaks the ecosystem into silos. Documentation and examples for one runtime don‚Äôt work with the other runtimes.\nMoreover, much of the existing documentation on async Rust feels outdated or incomplete. For example, the async book remains in draft, with concepts like cancellation, timeouts, and FuturesUnordered yet to be covered. (There is an open pull request, though.)\nThat leaves us with a situation that is unsatisfactory for everyone involved:\nFor new users, it is a big ask to navigate this space and make future-proof decisions.\nFor experienced users and library maintainers, supporting multiple runtimes is an additional burden. It‚Äôs no surprise that popular crates like reqwest simply insist on Tokio as a runtime.\nThis close coupling, recognized by the async working group, has me worried about its potential long-term impact on the ecosystem.\nThe case of async-std\nasync-std was an attempt to create an alternative runtime that is closer to the Rust standard library. Its promise was that you could almost use it as a drop-in replacement.\nTake, for instance, this straightforward synchronous file-reading code:\nuse std::fs::File;\nuse std::io::Read;\n\nfn main() -> std::io::Result<()> {\n    let mut file = File::open(\"foo.txt\")?;\n    let mut data = vec![];\n    file.read_to_end(&mut data)?;\n    Ok(())\n}\nIn async-std, it is an async operation instead:\nuse async_std::prelude::*;\nuse async_std::fs::File;\nuse async_std::io;\n\nasync fn read_file(path: &str) -> io::Result<()> {\n    let mut file = File::open(path).await?;\n    let mut data = vec![];\n    file.read_to_end(&mut data).await?;\n    Ok(())\n}\nThe only difference is the await keyword.\nWhile the name might suggest it, async-std is not a drop-in replacement for the standard library as there are many subtle differences between the two.\nHere are some examples of issues that are still open:\nNew thread is spawned for every I/O request\nOpenOptionsExt missing for Windows?\nSpawned task is stuck during flushing in File.drop()\nIt is hard to create a runtime that is fully compatible with the standard library. Even if it were a drop-in replacement, I‚Äôd still ponder its actual merit.\nRust is a language that values explicitness. This is especially true for reasoning about runtime behavior, such as allocations and blocking operations. The async-std‚Äôs teams proposal to ‚ÄúStop worrying about blocking‚Äù was met with noticeable community skepticism and later retracted.\nAs of this writing, 1754 public crates have a dependency on async-std and there are companies that rely on it in production.\nHowever, looking at the commits over time async-std is essentially abandoned as there is no active development anymore:\nThis leaves those reliant on the async-std API ‚Äì be it for concurrency mechanisms, extension traits, or otherwise ‚Äì in an unfortunate situation, as is the case for libraries developed on top of async-std, such as surf. The core of async-std is now powered by smol, but it is probably best to use it directly for new projects.\nCan‚Äôt we just embrace Tokio?\nTokio stands as Rust‚Äôs canonical async runtime. But to label Tokio merely as a runtime would be an understatement. It has extra modules for fs, io, net, process- and signal handling and more. That makes it more of a framework for asynchronous programming than just a runtime.\nPartially, this is because Tokio had a pioneering role in async Rust. It explored the design space as it went along. And while you could exclusively use the runtime and ignore the rest, it is easier and more common to buy into the entire ecosystem.\nYet, my main concern with Tokio is that it makes a lot of assumptions about how async code should be written and where it runs.\nFor example, at the beginning of the Tokio documentation, they state:\n‚ÄúThe easiest way to get started is to enable all features. Do this by enabling the full feature flag‚Äù:\ntokio = { version = \"1\", features = [\"full\"] }\nBy doing so, one would set up a work-stealing, multi-threaded runtime which mandates that types are Send and 'static and makes it necessary to use synchronization primitives such as Arc and Mutex for all but the most trivial applications.\nUnderstanding ‚Äôstatic Lifetimes in Async Rust\nA 'static trait bound mandates that the type does not contain any non-static references. This means the receiver can hold on to the type indefinitely without it becoming invalid until they decide to drop it.\nHere is an example of an async function that has a 'static lifetime bound:\nasync fn process_data<T: 'static>(data: T) {\n    // ...\n}\nOwned data passes a 'static lifetime bound if it, and all of its contents, do not contain any non-static references ‚Äî but, crucially, a reference to that owned data generally does not.\nSince tasks in async runtimes may outlive the scope they were created in (especially in multi-threaded contexts), ensuring that references remain valid for the duration of the task‚Äôs execution is challenging. This is why async tasks often require 'static data, to guarantee that the data lives long enough or to ensure ownership is transferred to the task.\nThis makes it hard to use references in async code, as borrowed data must live as long as the task.\nFor most practical use-cases, this means that futures cannot borrow data from the scope they are spawned from, unless the data lives long enough or ownership is transferred.\nThis requirement marks a significant departure from synchronous Rust, where borrowing data across function calls is commonplace. It represents a fundamental shift in how we manage data lifetimes and ownership in asynchronous compared to synchronous Rust.\nThe Original Sin of Rust async programming is making it multi-threaded by default. If premature optimization is the root of all evil, this is the mother of all premature optimizations, and it curses all your code with the unholy Send + 'static, or worse yet Send + Sync + 'static, which just kills all the joy of actually writing Rust.\n‚Äî Maciej Hirsz\nAny time we reach for an Arc or a Mutex it‚Äôs good idea to stop for a moment and think about the future implications of that decision.\nThe choice to use Arc or Mutex might be indicative of a design that hasn‚Äôt fully embraced the ownership and borrowing principles that Rust emphasizes. It‚Äôs worth reconsidering if the shared state is genuinely necessary or if there‚Äôs a simpler design that could minimize or eliminate the need for shared mutable state (for instance by using channels).\nThe problem, of course, is that Tokio imposes this design on you. It‚Äôs not your choice to make.\nBeyond the complexities of architecting async code atop these synchronization mechanisms, they carry a performance cost: Locking means runtime overhead and additional memory usage; in embedded environments, these mechanisms are often not available at all.\nMulti-threaded-by-default runtimes cause accidental complexity completely unrelated to the task of writing async code.\nFutures should be designed for brief, scoped lifespans rather than the 'static lifetime. Ideally, we‚Äôd lean on an explicit spawn::async instead of spawn::blocking.\nMaciej suggested to use a local async runtime which is single-threaded by default and does not require types to be Send and 'static.\nI fully agree.\nHowever, I have little hope that the Rust community will change course at this point. Tokio‚Äôs roots run deep within the ecosystem and it feels like for better or worse we‚Äôre stuck with it.\nIn the realms of networking and web operations, it‚Äôs likely that one of your dependencies integrates Tokio, effectively nudging you towards its adoption. At the time of writing, Tokio is used at runtime in 20,768 crates (of which 5,245 depend on it optionally).\nIn spite of all this, we should not stop innovating in the async space!\nOther Runtimes\nGoing beyond Tokio, several other runtimes deserve more attention:\nsmol: A small async runtime, which is easy to understand. The entire executor is around 1000 lines of code with other parts of the ecosystem being similarly small.\nembassy: An async runtime for embedded systems.\nglommio: An async runtime for I/O-bound workloads, built on top of io_uring and using a thread-per-core model.\nThese runtimes are important, as they explore alternative paths or open up new use cases for async Rust. Drawing a parallel with Rust‚Äôs error handling story, the hope is that competing designs will lead to a more robust foundation overall. Especially, iterating on smaller runtimes that are less invasive and single-threaded by default can help improve Rust‚Äôs async story.\nAsync vs Threads\nIf you don‚Äôt need async for performance reasons, threads can often be the simpler alternative. ‚Äî the Async Book\nModern operating systems come with highly optimized schedulers that are excellent at multitasking and support async I/O through io_uring and splice. We should make better use of these capabilities. At least we should fully lean into the capabilities of modern operating systems.\nTake our sync code to read a file from above for example. We can call this function inside the new scoped threads:\nuse std::error::Error;\nuse std::fs;\nuse std::io::Read;\nuse std::path::Path;\nuse std::{thread, time};\n\nfn main() {\n    thread::scope(|scope| {\n        // worker thread 1\n        scope.spawn(|| {\n            let contents = fs::read_to_string(\"foo.txt\");\n            // do something with contents\n        });\n\n        // worker thread 2\n        scope.spawn(|| {\n            let contents = fs::read_to_string(\"bar.txt\");\n            // ...\n        });\n\n        // worker thread 3\n        scope.spawn(|| {\n            let contents = fs::read_to_string(\"baz.txt\");\n            // ...\n        });\n    });\n    \n    // No join; threads get joined\n    // automatically once the scope ends\n}\n(Link to playground)\nOr, perhaps more aptly,\nfn main() {\n    let files = [\"foo.txt\", \"bar.txt\", \"baz.txt\"];\n    thread::scope(|scope| {\n        for file in files {\n            scope.spawn(move || {\n                let contents = fs::read_to_string(file);\n                // ...\n            });\n        }\n    });\n}\nIf this code were placed into a function, it would serve both synchronous and asynchronous callers, completely removing the need for an asynchronous runtime. The scheduling burden would shift to the operating system.\nAsync Rust promises efficient resource handling, at the cost of complexity and worse ergonomics. As an example, if the function were async and you called it outside of a runtime, it would compile, but not run. Futures do nothing unless being polled; a common footgun for newcomers.\nuse tokio::fs;\n\n#[tokio::main]\nasync fn main() {\n    // This will print a warning, but compile\n    // and do nothing at runtime\n    fs::read_to_string(\"foo.txt\");\n}\n(Link to playground)\nIf you find yourself needing to share state between threads, consider using a channel:\nuse std::error::Error;\nuse std::fs;\nuse std::io::Read;\nuse std::path::Path;\nuse std::{thread, time};\nuse std::sync::mpsc;\n\nfn main() {\n    let (tx, rx) = mpsc::channel::<String>();\n\n    let files = [\"foo.txt\", \"bar.txt\", \"baz.txt\"];\n\n    thread::scope(|scope| {\n        for file in files {\n            scope.spawn(move || {\n                let contents = fs::read_to_string(file);\n                // ...\n            });\n        }\n    });\n\n    // Receive messages from the channel\n    for received in rx {\n        println!(\"Got: {:?}\", received);\n    }\n}\n(Link to playground)\nCommon Prejudice Against Threads\nAsynchronous programming is often seen as the solution to improving performance and scalability of I/O-bound workloads.\nIn a recent benchmark, traditional threading outperformed the async approach in scenarios with a limited number of threads. This underscores the core premise that, in real-world applications, the performance difference between the two approaches is often negligible, if not slightly favoring threads. Thus, it‚Äôs crucial not to gravitate towards async Rust driven solely by anticipated performance gains.\nThread-based frameworks, like the now-inactive iron, showcased the capability to effortlessly handle tens of thousands of requests per second. This is further complemented by the fact modern Linux systems can manage tens of thousands of threads.\nTraditional arguments against threads simply don‚Äôt apply to Rust. Threaded code in Rust is protected from data races, null dereferences, and dangling references, ensuring a level of safety that prevents many common pitfalls found in other languages.\nAs an important caveat, threads are not available or feasible in all environments, such as embedded systems. My context for this article is primarily conventional server-side applications that run on top of platforms like Linux or Windows.\nSummary\nUse Async Rust Sparingly\nMy original intention was to advise newcomers to sidestep async Rust for now, giving the ecosystem time to mature. However, I since acknowledged that this is not feasible, given that a lot of libraries are async-first and new users will encounter async Rust one way or another.\nInstead, I would recommend to use async Rust only when you really need it. Learn how to write good synchronous Rust first and then, if necessary, transition to async Rust. Learn to walk before you run.\nIf you have to use async Rust, stick to Tokio and well-established libraries like reqwest and sqlx.\nWhile it may seem surprising given the context of this article, we can‚Äôt overlook Tokio‚Äôs stronghold within the ecosystem. A vast majority of libraries are tailored specifically for it. Navigating compatibility crates can pose challenges, and sidestepping Tokio doesn‚Äôt guarantee your dependencies won‚Äôt bring it in. I‚Äôm hoping for a future shift towards leaner runtimes, but for now, Tokio stands out as the pragmatic choice for real-world implementations.\nHowever, it‚Äôs valuable to know that there are alternatives to Tokio and that they are worth exploring.\nConsider The Alternatives\nAt its core, Rust and its standard library offer just the absolute essentials for async/await. The bulk of the work is done in crates developed by the Rust community. We should make more use of the ability to iterate on async Rust and experiment with different designs before we settle on a final solution.\nIn binary crates, think twice if you really need to use async. It‚Äôs probably easier to just spawn a thread and get away with blocking I/O. In case you have a CPU-bound workload, you can use rayon to parallelize your code.\nIsolate Async Code\nIf async is truly indispensable, consider isolating your async code from the rest of your application.\nKeep your domain logic synchronous and only use async for I/O and external services. Following these guidelines will make your code more composable and accessible. On top of that, the error messages of sync Rust are much easier to reason about than those of async Rust.\nIn your public library code, avoid async-only interfaces to make downstream integration easier.\nKeep It Simple\nAsync Rust feels like a different dialect, that is significantly more brittle than the rest of the language at the moment.\nWhen writing libraries, the maintenance overhead of supporting both async and sync interfaces is not to be underestimated.\nThe default mode for writing Rust should be synchronous. Freely after Stroustrup:\nInside Rust, there is a smaller, simpler language that is waiting to get out. It is this language that most Rust code should be written in.\nRevision notes: In an earlier version of this article, I discussed async web frameworks. However, to maintain focus, I‚Äôve opted to address web frameworks in a dedicated follow-up article. Furthermore, I‚Äôve added some clarifications regarding the performance characteristics of async Rust after a discussion on Hacker News. I‚Äôve also extended the section on scoped threads for clarity.\nPublished: 2024-02-21\nLast updated: 2024-04-27\nAuthor: Matthias Endler\nEditor: Simon Br√ºggen\nIdiomatic Rust content. Straight to your inbox.\nI regularly write new articles on idiomatic Rust. If you want to be notified when I publish them, you should sign up to my newsletter here. No spam. Unsubscribe at any time.\n‚Üë\nBack to top"},{"title":"The State of Async Rust: Runtimes : r/rust","link":"https://www.reddit.com/r/rust/comments/16p47f1/the_state_of_async_rust_runtimes/","content":"Back\nGo to rust\nr/rust\n‚Ä¢\n2 yr. ago\nPump1IT\nThe State of Async Rust: Runtimes\nüß† educational\ncorrode.dev\nOpen\nUpvote\n191\nDownvote\n69\nGo to comments\nAdd a comment\nSort by:\nBest\nSearch Comments\nExpand comment search\nClear search\nComments Section\noconnor663\n‚Ä¢\n2y ago\nThe choice to use Arc or Mutex might be indicative of a design that hasn't fully embraced the ownership and borrowing principles that Rust emphasizes.\nIt seems like there's a second Intermediate Rust Rule of Thumb coming along. The first one was \"use indexes instead of references when you run into lifetime issues.\" And now maybe the second one is \"use channels instead of Arc/Mutex when you have lots of shared state\"? In both cases, the first way of doing things is completely reasonable in small doses, but maybe not the best way to architect a big complicated application?\nUpvote\n25\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\nrousbound\n‚Ä¢\n2y ago\nHey, could you please elaborate more about the two cases you mentioned? Or maybe provide some resources about their disction? I'm referring to the indexes vs references and channels vs arc/mutex matter.\nAlso maybe sharing why you think they don't scale so well.\nI think you touched on two important subjects.\nThanks!\nUpvote\n4\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\n2 more replies\nVorpalWay\n‚Ä¢\n2y ago\nI feel like the discussion here is very confused and antagonist. Many people are saying that \"X is the future because Y and Z\", with different X, Y and Z. No one is recognising that different use cases have different needs.\nAnd if I started to say that embassy (embedded async) was the future of async rust no one would take me seriously (and rightly so). Embassy might be the future of embedded async (when you don't need hard realtime), but it absolutely needs that qualifier.\nI work in safety critical hard real time systems. That sort of code has extremely different needs than a IO bound web server, which has different needs than a computation heavy server, or async code in GUI or a game.\nI don't think one model can fit everyone. But the standard library (or a crate) should step up and offer foundational traits to make things interoperable so users can use the framework that best fit them, with the libraries that best fit them, and avoid combinatorial explosions.\nMaybe take inspiration from embedded-hal, which is a crate for embedded that abstracts over different micro controllers, letting me write a driver for e.g. an I2C peripheral once, and reuse it on many different microcontrollers, even though the way you talk to the I2C bus on the various microcontrollers varies wildly.\nUpvote\n19\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\ntheviciousfish\n‚Ä¢\n2y ago\nMaitake is a new no-std embedded async currently under development\nUpvote\n4\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\ncarllerche\n‚Ä¢\n2y ago\nTokio provides spawn_local which does not require Send. It takes a bit of setup to use, but IMO if you are using \"thread per core\" and share nothing, you are getting yourself into a \"more setup required\" situation as you need to start caring about a bunch of other details eg:\nHow to evenly distribute work across the various threads.\nHow to handle communication across threads (lets be honest, you will often need some sort of communication).\nwhat do you do if your threads handle very uneven work loads\netc...\nUpvote\n12\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\nbuldozr\n‚Ä¢\n2y ago\nOn async-std: even at the time when it was actively developed, it felt like a project driven by hype more than solid engineering. The whole premise of \"just like std, only async!\" was flawed: no, the async space is different, it needs different APIs, more than a super-easy learning curve for programmers who've only learned std! Some design decisions, like auto-starting a runtime under the hood on demand, did not play well with applications that did not expect such surprises occurring due to use of their dependency libraries. The heavy publicizing in the community, the rush to release 1.0, and much-hyped benchmarks vs. Tokio that IIRC did not stand up to scrutiny did not help winning over enough developer mind share either. Since the original movers have drifted away, there's not much interest in moving the project forward.\nUpvote\n40\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\n1 more reply\nteerre\n‚Ä¢\n2y ago\n‚Ä¢\nEdited 2y ago\nTop 1% Commenter\nThe future, hell, the present, is multithreaded, telling people to use anything singlethreaded is a disservice. (Edit: I misunderstood what the author meant with \"single threaded\")\nThat aside, this discussion about complexity is very complex. The author says in multiple ways that shared state manifested into Arcs and Mutexes introduces complexity in a variety of ways, yet I'm quite sure that the vast majority of people introducing these primitives do so because thinking of a design that doesn't use them would be too complicated.\nMaybe what Rust lacks is some abstraction over channels or maybe even something more industrial like Erlang's BEAM so that people don't immediately think Arc is the easiest answer. Path of least resistance and all that.\nUpvote\n27\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\nadnanclyde\n‚Ä¢\n2y ago\nMutex is something that should be avoided in high level code.\nWith async rust I always start off with an actor style design. Not something with strict limitations of an actor library, more a \"make every system live in its own spawned task and only expose handlers to it that communicate via message passing\".\nI could build quite complex systems this way without even having to think about the grander architecture. Additionally, you never think about cancellation safety as long as you limit the `select` calls to selecting input message sources (which is very easy to do).\nThe actor design approach thrives in the async world.\nUpvote\n41\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\n4 more replies\nKobzol\n‚Ä¢\n2y ago\nTop 1% Commenter\nThose are two different things. You can use a single threaded executor per core, and have both multithreading, simpler code and less contention. Everything doesn't need workstealing.\nUpvote\n39\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\n10 more replies\nlightmatter501\n‚Ä¢\n2y ago\nI would say the future is thread-per-core.\nLess resource contention is good for performance.\nUpvote\n10\nDownvote\nReply\nreply\nAward\nShare\nShare\nShare\n1 more reply"},{"title":"Tokio - An asynchronous Rust runtime","link":"https://tokio.rs/","content":"Tokio's APIs are memory-safe, thread-safe, and misuse-resistant. This helps prevent common bugs, such as unbounded queues, buffer overflows, and task starvation."},{"title":"GitHub - smol-rs/smol: A small and fast async runtime for Rust","link":"https://github.com/smol-rs/smol","content":"smol\nA small and fast async runtime.\nThis crate simply re-exports other smaller async crates (see the source).\nTo use tokio-based libraries with smol, apply the async-compat adapter to futures and I/O types.\nSee the smol-macros crate if you want a no proc-macro, fast compiling, easy-to-use async main and/or multi-threaded Executor setup out of the box.\nExamples\nConnect to an HTTP website, make a GET request, and pipe the response to the standard output:\nuse smol::{io, net, prelude::*, Unblock};\n\nfn main() -> io::Result<()> {\n    smol::block_on(async {\n        let mut stream = net::TcpStream::connect(\"example.com:80\").await?;\n        let req = b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\nConnection: close\\r\\n\\r\\n\";\n        stream.write_all(req).await?;\n\n        let mut stdout = Unblock::new(std::io::stdout());\n        io::copy(stream, &mut stdout).await?;\n        Ok(())\n    })\n}\nThere's a lot more in the examples directory.\nSubcrates\nasync-channel - Multi-producer multi-consumer channels\nasync-executor - Composable async executors\nasync-fs - Async filesystem primitives\nasync-io - Async adapter for I/O types, also timers\nasync-lock - Async locks (barrier, mutex, reader-writer lock, semaphore)\nasync-net - Async networking primitives (TCP/UDP/Unix)\nasync-process - Async interface for working with processes\nasync-task - Task abstraction for building executors\nblocking - A thread pool for blocking I/O\nfutures-lite - A lighter fork of futures\npolling - Portable interface to epoll, kqueue, event ports, and wepoll\nTLS certificate\nSome code examples are using TLS for authentication. The repository contains a self-signed certificate usable for testing, but it should not be used for real-world scenarios. Browsers and tools like curl will show this certificate as insecure.\nIn browsers, accept the security prompt or use curl -k on the command line to bypass security warnings.\nThe certificate file was generated using minica and openssl:\nminica --domains localhost -ip-addresses 127.0.0.1 -ca-cert certificate.pem\nopenssl pkcs12 -export -out identity.pfx -inkey localhost/key.pem -in localhost/cert.pem\nAnother useful tool for making certificates is mkcert.\nMSRV Policy\nThe Minimum Supported Rust Version (MSRV) of this crate is 1.63. As a tentative policy, the MSRV will not advance past the current Rust version provided by Debian Stable. At the time of writing, this version of Rust is 1.63. However, the MSRV may be advanced further in the event of a major ecosystem shift or a security vulnerability.\nLicense\nLicensed under either of\nApache License, Version 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0)\nMIT license (LICENSE-MIT or http://opensource.org/licenses/MIT)\nat your option.\nContribution\nUnless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions."}]"#;
                    println!(
                        "AI ÊêúÁ¥¢Âä©Êâã: {}",
                        web_search_json
                    );
                    // ÊûÑÈÄ†Êñ∞ÁöÑ FlowMessageÔºåÂ∞ÜÂΩìÂâçËäÇÁÇπÁöÑÂ§ÑÁêÜÁªìÊûúÂ°´ÂÖ• result Â≠óÊÆµ
                    let new_flow_msg = FlowMessage {
                        workflow_id: flow_msg.workflow_id.clone(),
                        node_id: "web_search".to_string(),
                        input: flow_msg.input.clone(),
                        prev_result: flow_msg.result.clone(),
                        result: Some(serde_json::from_str(web_search_json)
                            .unwrap_or(serde_json::Value::String(web_search_json.to_string()))),
                        aggregated: None,
                    };

                    // Áªü‰∏Ä‰º†Ëæì FlowMessage Êï∞ÊçÆ
                    node.send_output(
                        result_id(app_id.as_str()),
                        metadata.parameters,
                        new_flow_msg.into_arrow(),
                    )?;
                    println!("üîç web-search finished");

                }
                "init" => {
                    println!("üîç web-search started");

                    node.send_output(register_id(app_id.as_str()), metadata.parameters, NodeDescriptor{
                        id: app_id.to_string(),
                        description: "‰ΩøÁî®ÊµèËßàÂô®ÊâßË°åÊêúÁ¥¢ÔºåÂπ∂Ëß£ÊûêÊêúÁ¥¢ÁªìÊûú".to_string(),
                        inputs: serde_json::to_string_pretty(&schemars::schema_for!(SearchWebArgs)).unwrap(),
                        outputs: serde_json::to_string_pretty(&schemars::schema_for!(SearchResult)).unwrap(),
                        aggregate: false,
                    }.into_arrow())?;
                    println!("üîç web-search registered");
                }
                other => eprintln!("Ignoring unexpected input `{other}`"),
            },
            Event::Stop => {
                println!("Received manual stop");
                break;
            }
            Event::InputClosed { id } => {
                println!("Input `{id}` was closed");
            }
            other => eprintln!("Received unexpected input: {other:?}"),
        }
    }

    Ok(())
}
